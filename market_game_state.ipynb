{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83d\udcca Market Game State Inference\n", "This notebook analyzes historical market data (SPY and QQQ) using game theory to infer the most likely strategic regime (e.g., Prisoner's Dilemma, Chicken, Battle of the Sexes)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Install dependencies (Colab only)\n", "!pip install yfinance numpy pandas scipy --quiet"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import yfinance as yf\n", "import numpy as np\n", "import pandas as pd\n", "from scipy.optimize import minimize\n", "from scipy.special import softmax"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# --- STEP 1: Download and prepare market data ---\n", "tickers = ['SPY', 'QQQ']\n", "raw = yf.download(tickers, start=\"2022-01-01\", end=\"2023-01-01\", auto_adjust=True)\n", "\n", "# --- STEP 1B: Safely extract adjusted close prices ---\n", "try:\n", "    data = raw['Adj Close']\n", "except KeyError:\n", "    try:\n", "        data = raw['Close']\n", "    except KeyError:\n", "        raise ValueError(\"Neither 'Adj Close' nor 'Close' found. Try re-downloading without auto_adjust.\")\n", "\n", "data.columns = tickers\n", "returns = data.pct_change().dropna()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# --- STEP 2: Classify daily outcomes ---\n", "def classify(row):\n", "    if row['SPY'] > 0 and row['QQQ'] > 0:\n", "        return 'LL'\n", "    elif row['SPY'] > 0 and row['QQQ'] < 0:\n", "        return 'LS'\n", "    elif row['SPY'] < 0 and row['QQQ'] > 0:\n", "        return 'SL'\n", "    else:\n", "        return 'SS'\n", "\n", "returns['Outcome'] = returns.apply(classify, axis=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# --- STEP 3: QRE inference ---\n", "outcomes = ['LL', 'LS', 'SL', 'SS']\n", "freqs = returns['Outcome'].value_counts(normalize=True).reindex(outcomes, fill_value=0)\n", "joint_probs = freqs.to_numpy()\n", "\n", "if np.count_nonzero(joint_probs) < 3:\n", "    raise ValueError(\"Too few distinct outcomes to infer preferences. Try more data.\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def qre_probs(u, lam=1.5):\n", "    EU_I_L = u[0]*joint_probs[0] + u[1]*joint_probs[1]\n", "    EU_I_S = u[2]*joint_probs[2] + u[3]*joint_probs[3]\n", "    pI_L = np.exp(lam * EU_I_L)\n", "    pI_S = np.exp(lam * EU_I_S)\n", "    pI_L /= (pI_L + pI_S)\n", "\n", "    EU_II_L = u[4]*joint_probs[0] + u[6]*joint_probs[2]\n", "    EU_II_S = u[5]*joint_probs[1] + u[7]*joint_probs[3]\n", "    pII_L = np.exp(lam * EU_II_L)\n", "    pII_S = np.exp(lam * EU_II_S)\n", "    pII_L /= (pII_L + pII_S)\n", "\n", "    return np.array([\n", "        pI_L * pII_L,\n", "        pI_L * (1 - pII_L),\n", "        (1 - pI_L) * pII_L,\n", "        (1 - pI_L) * (1 - pII_L)\n", "    ])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def kl_divergence(p_obs, p_model):\n", "    return np.sum(p_obs * np.log((p_obs + 1e-8) / (p_model + 1e-8)))\n", "\n", "def loss(u):\n", "    return kl_divergence(joint_probs, qre_probs(u))\n", "\n", "res = minimize(loss, np.random.randn(8), method='BFGS')\n", "u_opt = res.x\n", "\n", "payoffs_I = dict(zip(outcomes, u_opt[:4]))\n", "payoffs_II = dict(zip(outcomes, u_opt[4:]))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# --- STEP 4: Rank preferences and infer game ---\n", "def rank(p_dict):\n", "    return [k for k, _ in sorted(p_dict.items(), key=lambda x: -x[1])]\n", "\n", "rank_I = rank(payoffs_I)\n", "rank_II = rank(payoffs_II)\n", "\n", "games = {\n", "    'Prisoners Dilemma': (['SL', 'LL', 'SS', 'LS'], ['LS', 'LL', 'SS', 'SL']),\n", "    'Chicken':           (['LS', 'LL', 'SL', 'SS'], ['SL', 'LL', 'LS', 'SS']),\n", "    'Battle of the Sexes': (['LL', 'SS', 'LS', 'SL'], ['SS', 'LL', 'SL', 'LS']),\n", "}\n", "\n", "def score_match(r1, r2, g1, g2):\n", "    return sum([r1[i] == g1[i] for i in range(4)]) + sum([r2[i] == g2[i] for i in range(4)])\n", "\n", "scores = {name: score_match(rank_I, rank_II, g1, g2) for name, (g1, g2) in games.items()}\n", "best_game = max(scores.items(), key=lambda x: x[1])\n", "score_vals = np.array(list(scores.values()), dtype=float)\n", "score_probs = softmax(score_vals)\n", "score_names = list(scores.keys())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# --- STEP 5: Display Results ---\n", "print(\"\\n=== Inferred Preference Ranking ===\")\n", "print(\"Player I:\", rank_I)\n", "print(\"Player II:\", rank_II)\n", "\n", "print(\"\\n=== Best Matching Game ===\")\n", "print(\"Game Type:\", best_game[0])\n", "print(\"Match Score:\", best_game[1], \"/ 8\")\n", "\n", "print(\"\\n=== Game Type Probabilities (Softmax) ===\")\n", "for name, prob in zip(score_names, score_probs):\n", "    print(f\"{name}: {prob:.3f}\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 5}